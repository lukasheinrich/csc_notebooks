{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306801fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b64457",
   "metadata": {},
   "source": [
    "# Part 1 - Understanding Convolutions\n",
    "\n",
    "In this exercise we will look more into ConvNets\n",
    "\n",
    "As discussed in the lecture, the key ideas to convnets are local connectivity and weight sharing which lead us to convolutions.\n",
    "\n",
    "Before trying to *learn* convolutional filters, let's manually construct them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c661a",
   "metadata": {},
   "source": [
    "## Step 1 - Image Processing\n",
    "\n",
    "Write a function that downloads an image at a given URL and converts it into greyscale and returns a 2D array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cbbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e319786",
   "metadata": {},
   "source": [
    "## Step 2 - the `torch.nn.Conv2D` object\n",
    "\n",
    "Research how to access the parameters of the convolution kernel module `torch.nn.Conv2D` in PyTorch and make sure you understand where \n",
    "kernel size, input channels and output channels come into definint the shape of the parameter tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46831f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b15edb8e",
   "metadata": {},
   "source": [
    "## Step 3 - Manually creating Convolutions\n",
    "\n",
    "Create a `Conv2D` module with 1 input channel and 2 output channels with kernel size 3\n",
    "\n",
    "* set the weights of of first output channel is a vertical edge detector\n",
    "* set the weights of the second output channel is a horizontal edge detector\n",
    "* create a size 1 input batch with a greyscale image of your choice and visualize the outputss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4f95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3cafe0",
   "metadata": {},
   "source": [
    "## Step 4 - Use a pre-trained network do analyze an image of your choice\n",
    "\n",
    "* Check out the following link, and try using the famour `inception_v3` model to process an image of your choice\n",
    "* https://pytorch.org/hub/pytorch_vision_inception_v3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b311739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d37efe",
   "metadata": {},
   "source": [
    "# Part 2 - Training Convolutional Nets\n",
    "\n",
    "## Step 1 - Download the MNIST Dataset\n",
    "\n",
    "The \"Hello World\" of convolutional neural networks are MNIST images. You can get the training data by\n",
    "running the following command in `pip`\n",
    "\n",
    "```\n",
    "pip install mnist\n",
    "```\n",
    "\n",
    "and get e.g. the training data (there is a separate validation dataset). \n",
    "\n",
    "Here is simple code to sample minibatches from the training of validation dataset (not the simple preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ccf80ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = mnist.train_labels()\n",
    "test_labels = mnist.test_labels()\n",
    "scale_mean, scale_std = mnist.train_images().mean(),mnist.train_images().std()\n",
    "train_images = (mnist.train_images()-scale_mean)/scale_std\n",
    "test_images = (mnist.test_images()-scale_mean)/scale_std\n",
    "\n",
    "def make_batch(N = 300, collection = 'train'):\n",
    "    images = train_images if collection == 'train' else test_images\n",
    "    labels = train_labels if collection == 'train' else test_labels\n",
    "        \n",
    "    indices = np.random.choice(np.arange(len(images)), size = (N,), replace = True)\n",
    "    X = images[indices]\n",
    "    y = labels[indices]\n",
    "    return torch.FloatTensor(X[:,None]),torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7676ff",
   "metadata": {},
   "source": [
    "## Step 2 - Make a CNN\n",
    "\n",
    "Create a ConvNet with the following structure\n",
    "\n",
    "* Conv 5 x 5 ( 1 -> 16 channels) -> ReLU -> MaxPool 2 x 2\n",
    "* Conv 3 x 3 ( 16 -> 16 channels) -> ReLU -> MaxPool 2 x 2\n",
    "* Conv 2 x 2 ( 16 -> 32 channels) \n",
    "\n",
    "\n",
    "Find out what the output on a random MNIST-like torch tensor is, i.e. `x = torch.randn(123,1,28,28)`\n",
    "\n",
    "* Use `torch.nn.Flatten` to flatten all the remaining dimensions after the three convolutions into\n",
    "\n",
    "How big is this intermediate representation of an image?\n",
    "\n",
    "Finish the network by adding a head that ends with a `Linear(N,10)` layer (which we interpret to be the logits of the per-class probabilities).\n",
    "\n",
    "With such an output you can then evaluate the multi-class loss via (the softmax is done internally) \n",
    "\n",
    "```\n",
    "p = model(X)\n",
    "loss = torch.nn.functional.cross_entropy(p,y)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94810a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a9ecb02",
   "metadata": {},
   "source": [
    "## Step 3 - Train a CNN on MNIST\n",
    "\n",
    "Use this model now to train your neural network to recognize the digit in these 28,28 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af94b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f43ac46",
   "metadata": {},
   "source": [
    "## Step 4 - evaluate on the test set\n",
    "\n",
    "Sample a digit from the independent test set via\n",
    "\n",
    "X,y = make_batch(N = 1, collection='test')\n",
    "\n",
    "* Visualize the example\n",
    "* Run your model and turn the logits into probabilities via `torch.nn.functional.softmax`\n",
    "* Is the answer correct?\n",
    "\n",
    "\n",
    "\n",
    "* Check out the following link, and try using the famour `inception_v3` model to process an image of your choice\n",
    "* https://pytorch.org/hub/pytorch_vision_inception_v3/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ae529",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit ('garbargeml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ef91e534abe79302bcf2b7f1b029f2935bc4c6fa03da29571980ae05169f629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
