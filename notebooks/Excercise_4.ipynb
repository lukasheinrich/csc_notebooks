{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a06216",
   "metadata": {},
   "source": [
    "# Training an Autoencoder \n",
    "\n",
    "As discussed in the lecture, one of the standard self-supervised learning techniques is \"auto-encoding\", that is \n",
    "taking a datum $x$ to a \"code\" $c = f_\\phi(x)$ and reconstructing it again $x' = g_\\theta(c)$\n",
    "\n",
    "The training goal is to make the reconstruction as close as possible to the original: $L(x,x')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mnist\n",
    "import mnist\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2455b",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "Write an Autoencoder PyTorch module that has a latent space of dimension 2\n",
    "\n",
    "* a `encoder` submodule that is a MLP that can take `(N,28,28)` tensors and return \"encoded\" tensors of shape `(N,2)`\n",
    "* a `decoder` submodule that is also a MLP which \n",
    "\n",
    "* a `forward()` method that takes a batch of MNIST images and returns a 2-tuple with 1) the encoded  values and 2)  the reconstructed images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cbd78ed",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "Use `pip install mnist` to get access to the MNIST dataset and write a data-generating function\n",
    "`sample_train(N, return_labels = False)` that samples N instances from the training set\n",
    "\n",
    "optionally it should also return the labels (this is just for later, since we are doing unsupervised learning, we don't need the labels for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcee6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "791577b1",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Write a training loop with your Autoencoder model that trains using mini-batches of size 200 and using a standard mean-squared-error (MSE) loss. Train for 50k steps with learning rate 1e-3 (with Adam)\n",
    "\n",
    "**Optionally**: it's nice to track how the autoencoder is doing as you train.\n",
    "\n",
    "Write a plotting function `plot(model,samples)` that takes a mini batch of size 1 and plots both the original as well as the reconstructed images side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bea54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054643c6",
   "metadata": {},
   "source": [
    "# Step 4: Exploring the Latent Space\n",
    "\n",
    "Sample a mini batch of size 10,000 **with** labels and encode it into the latent space with the\n",
    "trained encoder. Since it's a 2-D latent space we can easily visualize it. Plot the distribution\n",
    "of codes as a scatter plot in the $(c_1,c_2)$-plane and color the markers according to the true label\n",
    "\n",
    "Observe how the individual clusters correspond among other things to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c83f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c7f17c",
   "metadata": {},
   "source": [
    "# Step 5: Generating new images\n",
    "\n",
    "Given the distribution in the latent space you should have a good feel, which type of code, \n",
    "corresponds to which digit.\n",
    "\n",
    "* Try to take a code that you think would generate a 4\n",
    "\n",
    "As you see, the distribution in the latetn space is a bit unruly, if you would\n",
    "\n",
    "* Generate a digit based on a random R^2 value\n",
    "\n",
    "you would have a hard time recognizing it as a digit. Try it!\n",
    "\n",
    "To fix this, we discussed in the lecture the idea of a \"Variational Autoencoder\" that tries\n",
    "to control the latent distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0f723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit ('garbargeml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ef91e534abe79302bcf2b7f1b029f2935bc4c6fa03da29571980ae05169f629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
